{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zugzwang03/nas_unet/blob/main/NAS_Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjN1GpKJCl-r",
        "outputId": "e8470b80-a1dd-42f8-bfa5-7e835f339ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdx6SbxcCt83",
        "outputId": "9a8ab0c9-9f19-4f8c-d75b-c1f22fac0991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load_from_folder(folder, img_size=(64, 64), grayscale=True):\n",
        "  images=[]\n",
        "  for filename in sorted(os.listdir(folder))[:10]:\n",
        "    path = os.path.join(folder, filename)\n",
        "    img = load_img(path, target_size=img_size, color_mode='grayscale' if grayscale else 'rgb')\n",
        "    img_array = img_to_array(img)\n",
        "    images.append(img_array)\n",
        "  return np.array(images)"
      ],
      "metadata": {
        "id": "z7gyAitOMRwR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder='/content/drive/MyDrive/PROMISE12/train_data/image'\n",
        "mask_folder='/content/drive/MyDrive/PROMISE12/train_data/mask'\n",
        "x_train = load_from_folder(img_folder, (64, 64), True)\n",
        "y_train = load_from_folder(mask_folder, (64, 64), True)\n",
        "y_train = (y_train > 0).astype(np.float32)"
      ],
      "metadata": {
        "id": "AY124zxYniOp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder='/content/drive/MyDrive/PROMISE12/test_data/image'\n",
        "mask_folder='/content/drive/MyDrive/PROMISE12/test_data/mask'\n",
        "x_test=load_from_folder(img_folder, (64, 64), True)\n",
        "y_test=load_from_folder(mask_folder, (64, 64), True)\n",
        "y_test = (y_test > 0).astype(np.float32)"
      ],
      "metadata": {
        "id": "MeFQY8zFXpAs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder='/content/drive/MyDrive/PROMISE12/validation_data/image'\n",
        "mask_folder='/content/drive/MyDrive/PROMISE12/validation_data/mask'\n",
        "x_val=load_from_folder(img_folder, (64, 64), True)\n",
        "y_val=load_from_folder(mask_folder, (64, 64), True)\n",
        "y_val = (y_val > 0).astype(np.float32)"
      ],
      "metadata": {
        "id": "2yOpFG2BiiZQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('x_train.npy', x_train)\n",
        "np.save('x_test.npy', x_test)\n",
        "np.save('x_val.npy', x_val)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('y_val.npy', y_val)"
      ],
      "metadata": {
        "id": "9pjVQ3MQnFFe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2MXynzuIqAy",
        "outputId": "5bdc1967-8126-437a-aed2-8aabcf24ed80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-O5oOAE9Ivaf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_unet_model(hp):\n",
        "    inputs = Input(shape=(64, 64, 1))  # Adjust input shape if needed\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(hp.Int('filters1', min_value=32, max_value=64, step=32), (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(hp.Int('filters1', min_value=32, max_value=64, step=32), (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(hp.Int('filters2', min_value=64, max_value=128, step=64), (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(hp.Int('filters2', min_value=64, max_value=128, step=64), (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(hp.Int('filters3', min_value=128, max_value=256, step=128), (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(hp.Int('filters3', min_value=128, max_value=256, step=128), (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(hp.Int('filters4', min_value=256, max_value=512, step=256), (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(hp.Int('filters4', min_value=256, max_value=512, step=256), (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = Conv2D(hp.Int('filters5', min_value=512, max_value=1024, step=512), (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(hp.Int('filters5', min_value=512, max_value=1024, step=512), (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    d4 = Conv2DTranspose(hp.Int('filters4', min_value=256, max_value=512, step=256), (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    d4 = concatenate([d4, c4])\n",
        "    c6 = Conv2D(hp.Int('filters4', min_value=256, max_value=512, step=256), (3, 3), activation='relu', padding='same')(d4)\n",
        "    c6 = Conv2D(hp.Int('filters4', min_value=256, max_value=512, step=256), (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    d3 = Conv2DTranspose(hp.Int('filters3', min_value=128, max_value=256, step=128), (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    d3 = concatenate([d3, c3])\n",
        "    c7 = Conv2D(hp.Int('filters3', min_value=128, max_value=256, step=128), (3, 3), activation='relu', padding='same')(d3)\n",
        "    c7 = Conv2D(hp.Int('filters3', min_value=128, max_value=256, step=128), (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    d2 = Conv2DTranspose(hp.Int('filters2', min_value=64, max_value=128, step=64), (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    d2 = concatenate([d2, c2])\n",
        "    c8 = Conv2D(hp.Int('filters2', min_value=64, max_value=128, step=64), (3, 3), activation='relu', padding='same')(d2)\n",
        "    c8 = Conv2D(hp.Int('filters2', min_value=64, max_value=128, step=64), (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    d1 = Conv2DTranspose(hp.Int('filters1', min_value=32, max_value=64, step=32), (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    d1 = concatenate([d1, c1])\n",
        "    c9 = Conv2D(hp.Int('filters1', min_value=32, max_value=64, step=32), (3, 3), activation='relu', padding='same')(d1)\n",
        "    c9 = Conv2D(hp.Int('filters1', min_value=32, max_value=64, step=32), (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fIGCUW_kI0GK"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    return build_unet_model(hp)\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=2,\n",
        "    hyperband_iterations=10,\n",
        "    directory='my_dir',\n",
        "    project_name='unet_nas'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s53xNgLcJBfQ",
        "outputId": "aab3683b-a1d6-4373-cecb-2d7429796395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.935791015625\n",
            "\n",
            "Best val_accuracy So Far: 0.935791015625\n",
            "Total elapsed time: 00h 06m 42s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    epochs=2,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2  # Or use a separate validation set\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iNFadatsJtg1",
        "outputId": "043e8872-a501-47e3-ec8c-b1b3ac049140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 94 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9609 - loss: 0.4534 - val_accuracy: 0.9341 - val_loss: 0.5152\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - accuracy: 0.9597 - loss: 0.4054 - val_accuracy: 0.9341 - val_loss: 0.4110\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 328ms/step - accuracy: 0.9612 - loss: 0.3853 - val_accuracy: 0.9341 - val_loss: 0.3807\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.9602 - loss: 0.2985 - val_accuracy: 0.9341 - val_loss: 3.3859\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.9604 - loss: 1.3164 - val_accuracy: 0.9661 - val_loss: 0.2911\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593ms/step - accuracy: 0.9745 - loss: 0.3171 - val_accuracy: 0.9395 - val_loss: 0.2921\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 319ms/step - accuracy: 0.9631 - loss: 0.2898 - val_accuracy: 0.9341 - val_loss: 0.4186\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - accuracy: 0.9595 - loss: 0.2669 - val_accuracy: 0.9341 - val_loss: 0.5199\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - accuracy: 0.9601 - loss: 0.2729 - val_accuracy: 0.9341 - val_loss: 0.4044\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.9611 - loss: 0.2211 - val_accuracy: 0.9617 - val_loss: 0.2169\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - accuracy: 0.9657 - loss: 0.3192\n",
            "Best Model - Loss: 0.3192168176174164, Accuracy: 0.9656738042831421\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "0.025875058\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFOklEQVR4nO3dMW6EMBRAQRxx/ys73atAYaWQ3ZiZElG4e/qyMWPOOTcA2Lbt690LAOBziAIAEQUAIgoARBQAiCgAEFEAIKIAQParL44x7lwHADe78q2ySQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg+7sXAHeZcx4+H2P88Urg/zApABBRACCiAEBEAYDYaOZxzjagX2XDmhWZFACIKAAQUQAgogBARAGAOH3EEn7rRBE8nUkBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDi7iOWcPQXNPchwetMCgBEFACIKAAQUQAgogBAnD6CHxydbIJVmRQAiCgAEFEAIKIAQGw0s6yzDWLXX8A5kwIAEQUAIgoARBQAiCgAEKePeBzXVsA5kwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDZr74457xzHQB8AJMCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgD5Bn01HBiq2yLJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [0.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [0.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]\n",
            "\n",
            "  [[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   ...\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]]\n"
          ]
        }
      ],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Train the U-Net model\n",
        "history = best_model.fit(x_train, y_train, batch_size=8, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(x_val, y_val)  # Assuming you have a validation set\n",
        "print(f\"Best Model - Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "y_out = best_model.predict(x_val)\n",
        "print(np.mean(y_out))\n",
        "y_out = (y_out > 7.463879e-14).astype(np.float32)\n",
        "plt.imshow(y_val[0], cmap='gray')\n",
        "plt.axis('off')  # To hide axis\n",
        "plt.show()\n",
        "plt.imshow(y_out[0], cmap='gray')\n",
        "plt.axis('off')  # To hide axis\n",
        "plt.show()\n",
        "print((y_out))\n",
        "# Optionally save the best model\n",
        "best_model.save('best_unet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yu9GDda9X9P4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb4fc99-22b5-4cbb-ce93-5ce458b7d592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict masks\n",
        "predictions = best_model.predict(x_test)\n",
        "\n",
        "# Post-process predictions\n",
        "# Assuming masks are binary (0 or 1), threshold the predictions\n",
        "predictions = (predictions > 7.463879e-14).astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lOI9aE39YDmu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_predictions(predictions, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    for i, pred in enumerate(predictions):\n",
        "        # Convert the prediction to an image\n",
        "        pred_image = pred.squeeze()  # Remove single-dimensional entries\n",
        "        pred_image = (pred_image * 255).astype(np.uint8)  # Scale to [0, 255] for saving as image\n",
        "        output_path = os.path.join(output_folder, f'pred_{i}.png')\n",
        "        plt.imsave(output_path, pred_image, cmap='gray')  # Save as grayscale image\n",
        "\n",
        "# Define output folder for predictions\n",
        "output_folder = '/content/drive/MyDrive/PROMISE12/output_data'  # Replace with your desired output folder path\n",
        "save_predictions(predictions, output_folder)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz4IPYUkNCLIjdxrOmKQEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}